{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d82c99fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "\n",
    "input_file_directory = \"./data/input_data/\"\n",
    "preprocessed_file_directory = \"./data/preprocessed_data/\"\n",
    "output_file_directory = \"./data/result_data/\"\n",
    "tss_data_directory = \"./data/custom_binned_tss_data/\"\n",
    "processed_file_directory = \"./data/processed_data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cadbd8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(df):\n",
    "    filtered_columns = df[speaker_cols]\n",
    "    df['speech_pattern'] = filtered_columns.astype(str).apply(lambda x: ','.join(x), axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b225f9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_tss_disjoint(df):\n",
    "    \n",
    "    queue = []\n",
    "    df['tss_disjoint'] = 0\n",
    "    df['queue_disjoint'] = ''\n",
    "\n",
    "    previous_speaker_set = set()\n",
    "    previous_speaker_pattern = ''\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        df.at[index, 'queue_disjoint'] = str(queue)\n",
    "        \n",
    "            \n",
    "        if previous_speaker_pattern and row['speech_pattern'] != previous_speaker_pattern :\n",
    "\n",
    "            new_speaker_set = set()\n",
    "            for speaker in speaker_cols:\n",
    "                if row[speaker]:\n",
    "                    new_speaker_set.add(speaker)\n",
    "                    \n",
    "            difference_set = new_speaker_set - previous_speaker_set \n",
    "            if len(difference_set):\n",
    "                queue += list(difference_set)\n",
    "\n",
    "                while len(queue)>3:\n",
    "                    queue.pop(0)\n",
    "\n",
    "                if len(set(queue)) == 3:\n",
    "                    df.at[index, 'tss_disjoint'] = 1\n",
    "                    queue = []\n",
    "\n",
    "            previous_speaker_set = new_speaker_set\n",
    "            \n",
    "        previous_speaker_pattern = row['speech_pattern']\n",
    "        \n",
    "            \n",
    "            \n",
    "    return df\n",
    "\n",
    "def identify_tss_disjoint_sp(df, MEDIAN_SP_THRESHOLD):\n",
    "    \n",
    "    queue = []\n",
    "    df[f'tss_disjoint_sp_{MEDIAN_SP_THRESHOLD}'] = 0\n",
    "    df[f'queue_disjoint_sp_{MEDIAN_SP_THRESHOLD}'] = ''\n",
    "\n",
    "    previous_speaker_set = set()\n",
    "    previous_speaker_pattern = ''\n",
    "    \n",
    "    pause_frame_count = 0\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        df.at[index, f'queue_disjoint_sp_{MEDIAN_SP_THRESHOLD}'] = str(queue)\n",
    "        \n",
    "        if row['Active Speaker Count'] == 0:\n",
    "            pause_frame_count += 1\n",
    "            \n",
    "            \n",
    "        if previous_speaker_pattern and row['speech_pattern'] != previous_speaker_pattern :\n",
    "            \n",
    "            if MEDIAN_SP_THRESHOLD is not None and pause_frame_count > MEDIAN_SP_THRESHOLD:\n",
    "                queue = []\n",
    "                pause_frame_count = 0\n",
    "\n",
    "            new_speaker_set = set()\n",
    "            for speaker in speaker_cols:\n",
    "                if row[speaker]:\n",
    "                    new_speaker_set.add(speaker)\n",
    "                    \n",
    "            difference_set = new_speaker_set - previous_speaker_set \n",
    "            if len(difference_set):\n",
    "                queue += list(difference_set)\n",
    "\n",
    "                while len(queue)>3:\n",
    "                    queue.pop(0)\n",
    "\n",
    "                if len(set(queue)) == 3:\n",
    "                    df.at[index, f'tss_disjoint_sp_{MEDIAN_SP_THRESHOLD}'] = 1\n",
    "                    queue = []\n",
    "\n",
    "            previous_speaker_set = new_speaker_set\n",
    "            \n",
    "        previous_speaker_pattern = row['speech_pattern']\n",
    "        \n",
    "            \n",
    "            \n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa1c9fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binning(df):\n",
    "    \n",
    "    # Calculate the number of bins required\n",
    "    bin_size = 1800\n",
    "    num_bins = (len(df) - 1) // bin_size + 1\n",
    "\n",
    "    # Create an empty list to store the DataFrames for each bin\n",
    "    result_dfs = []\n",
    "\n",
    "    # Loop through each bin and calculate the sum for each column\n",
    "    for bin_num in range(num_bins):\n",
    "        start_index = bin_num * bin_size\n",
    "        end_index = (bin_num + 1) * bin_size\n",
    "        bin_df = df.iloc[start_index:end_index]\n",
    "        bin_sum = bin_df.sum()\n",
    "        bin_sum['Frame'] = f\"{bin_num * bin_size + 1}-{min((bin_num + 1) * bin_size, len(df))}\"\n",
    "        result_dfs.append(bin_sum)\n",
    "\n",
    "    # Concatenate all the DataFrames in the result_dfs list into a single DataFrame\n",
    "    result_df = pd.concat(result_dfs, axis=1).T\n",
    "\n",
    "    # Set the 'Frame' column as the index of the result DataFrame\n",
    "    result_df.set_index('Frame', inplace=True)\n",
    "    result_df = result_df.reset_index(drop=True)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "\n",
    "def binning_plus(df):\n",
    "    # Calculate the number of bins required\n",
    "    bin_sizes = [5400] + [1800] * ((len(df) - 5400 - 1) // 1800 + 1)\n",
    "\n",
    "    # Create an empty list to store the DataFrames for each bin\n",
    "    result_dfs = []\n",
    "\n",
    "    # Loop through each bin and calculate the sum for each column\n",
    "    for bin_num, bin_size in enumerate(bin_sizes):\n",
    "        start_index = bin_num * bin_size\n",
    "        end_index = (bin_num + 1) * bin_size\n",
    "        bin_df = df.iloc[start_index:end_index]\n",
    "        bin_sum = bin_df.sum()\n",
    "        bin_sum['Frame'] = f\"{bin_num * bin_size + 1}-{min((bin_num + 1) * bin_size, len(df))}\"\n",
    "        result_dfs.append(bin_sum)\n",
    "\n",
    "    # Concatenate all the DataFrames in the result_dfs list into a single DataFrame\n",
    "    result_df = pd.concat(result_dfs, axis=1).T\n",
    "\n",
    "    # Set the 'Frame' column as the index of the result DataFrame\n",
    "    result_df.set_index('Frame', inplace=True)\n",
    "    result_df = result_df.reset_index(drop=True)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "\n",
    "\n",
    "def save_dataframe_as_bar_graph(df, save_filepath, title, ylabel, xlabel=\"Minute\"):\n",
    "    # Set a custom color palette for the bars\n",
    "    colors = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\", \"#8c564b\", \"#e377c2\", \"#7f7f7f\", \"#bcbd22\", \"#17becf\"]\n",
    "    sns.set_palette(colors)\n",
    "\n",
    "    # Increase the width of the bars\n",
    "    bar_width = 0.8\n",
    "    \n",
    "    df.set_index('Minute', inplace=True)\n",
    "\n",
    "    # Plotting the bar graph with or without outlining the bars\n",
    "    ax = df.plot(kind='bar', figsize=(10, 6), width=bar_width)\n",
    "\n",
    "    # Adding labels and title\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "\n",
    "    # Displaying the legend with custom labels\n",
    "    plt.legend(title='Columns', labels=df.columns)\n",
    "\n",
    "    # Removing the top and right spines for aesthetics\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "#     Show the plot\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "    # Save the graph at the specified location\n",
    "    plt.savefig(save_filepath)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3049ae01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/129 [00:17<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (31) does not match length of index (33)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m     df \u001b[38;5;241m=\u001b[39m binning_plus(df)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m#     df.insert(0, 'Minute', range(1, len(df) + 1))\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m     df\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinute\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0-3\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;28mlen\u001b[39m(df))])\n\u001b[0;32m     35\u001b[0m     group, speakers \u001b[38;5;241m=\u001b[39m filename[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m#     df.to_csv(f\"{tss_data_directory}/binned_tss_{filename}\", index=False)\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m#     save_dataframe_as_bar_graph(df, f\"{tss_data_directory}/binned_tss{filename[:-4]}_graph\", f\"Group: {group} ({speakers})\", \"Triadic Speech Seq. Count\")\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m#     display(df.head(20))\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4821\u001b[0m, in \u001b[0;36mDataFrame.insert\u001b[1;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[0;32m   4818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m   4819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloc must be int\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 4821\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sanitize_column(value)\n\u001b[0;32m   4822\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39minsert(loc, column, value)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4915\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4912\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   4914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 4915\u001b[0m     com\u001b[38;5;241m.\u001b[39mrequire_length_match(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\common.py:571\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m--> 571\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    572\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    573\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    576\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (31) does not match length of index (33)"
     ]
    }
   ],
   "source": [
    "tss_list = []\n",
    "speaker_cols = []\n",
    "\n",
    "MEDIAN_SP_THRESHOLDS = [2, 32, 34.9, 78.5]\n",
    "MEDIAN_SP_THRESHOLDS.sort(reverse=True)\n",
    "\n",
    "for filename in tqdm(os.listdir(preprocessed_file_directory)):\n",
    "    if '.csv' not in filename:\n",
    "        continue\n",
    "    file_path = preprocessed_file_directory +'/'+ filename\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    speaker_cols = []\n",
    "    for col in df.columns:\n",
    "        if 'Sub Id' in col:\n",
    "            speaker_cols.append(col)\n",
    "    \n",
    "    df = prep(df)\n",
    "    df = identify_tss_disjoint(df)\n",
    "    \n",
    "    for MEDIAN_SP_THRESHOLD in MEDIAN_SP_THRESHOLDS:\n",
    "        df = identify_tss_disjoint_sp(df, MEDIAN_SP_THRESHOLD)\n",
    "        \n",
    "    df = df[['Frame', 'tss_disjoint',\n",
    "       'tss_disjoint_sp_78.5', \n",
    "       'tss_disjoint_sp_34.9',  'tss_disjoint_sp_32', 'tss_disjoint_sp_2' ]]\n",
    "    \n",
    "    df.columns = ['Frame', 'Disjoint TSS Count',\n",
    "       'Disjoint TSS Count (Pause <= 78.5)', \n",
    "       'Disjoint TSS Count (Pause <= 34.9)',  'Disjoint TSS Count (Pause <= 32)', 'Disjoint TSS Count (Pause <= 2)' ]\n",
    "    df = binning_plus(df)\n",
    "#     df.insert(0, 'Minute', range(1, len(df) + 1))\n",
    "    df.insert(0, 'Minute', [f\"0-3\" if i == 3 else str(i) for i in range(3,len(df)+3)])\n",
    "\n",
    "    group, speakers = filename[:-4].split('_', 1)\n",
    "#     df.to_csv(f\"{tss_data_directory}/binned_tss_{filename}\", index=False)\n",
    "#     save_dataframe_as_bar_graph(df, f\"{tss_data_directory}/binned_tss{filename[:-4]}_graph\", f\"Group: {group} ({speakers})\", \"Triadic Speech Seq. Count\")\n",
    "#     display(df.head(20))\n",
    "    break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288d386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9c48bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a89941",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
