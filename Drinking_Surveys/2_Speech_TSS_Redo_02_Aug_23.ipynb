{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fde5693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "\n",
    "input_file_directory = \"D:/Program Files/Documents/CMU/Alcohol_Research/column_trim_data\"\n",
    "speech_data_directory = \"D:/Program Files/Documents/CMU/Alcohol_Research/speech_data\"\n",
    "binned_tss_directory = \"D:/Program Files/Documents/CMU/Alcohol_Research/binned_tss_data\"\n",
    "custom_binned_tss_directory = \"D:/Program Files/Documents/CMU/Alcohol_Research/custom_binned_tss_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a257cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def speech_formatting():\n",
    "#     desired_columns = ['Sub_ID', 'Frame', 'Speak']\n",
    "#     alternate_columns = ['Unnamed: 0','1','44']\n",
    "\n",
    "#     for filename in tqdm(os.listdir(input_file_directory)):\n",
    "#         if '.csv' not in filename:\n",
    "#             continue\n",
    "\n",
    "#         file_path = input_file_directory +'/'+ filename\n",
    "#         df = pd.read_csv(file_path)\n",
    "\n",
    "#         try:\n",
    "#             df = df[desired_columns]\n",
    "#         except Exception as e:\n",
    "#             if all(col in df.columns for col in alternate_columns):\n",
    "#                 df = df[alternate_columns]\n",
    "#                 print(f'File has different column names: ' + filename)\n",
    "#                 df.columns = desired_columns\n",
    "#             else:\n",
    "#                 print(f'CHECK THIS DF OUT: {filename}')\n",
    "        \n",
    "#         # Convert all columns to integers\n",
    "#         try:\n",
    "#             df = df.applymap(int)\n",
    "#         except:\n",
    "#             if '88_A2574_B2567_C2541' in filename:\n",
    "#                 df = df.replace(r'^\\s*$', 0, regex=True)\n",
    "#                 df = df.applymap(int)\n",
    "#             else:\n",
    "#                 print(f'Skipping file (int issue): {filename}')\n",
    "#                 # print(df.shape)\n",
    "#                 # display(df.head(200))\n",
    "#                 # display(df.tail(25))\n",
    "#                 continue\n",
    "        \n",
    "#         sub_ids = list(df['Sub_ID'].unique())\n",
    "    \n",
    "#         # Grouping by frame\n",
    "#         try:\n",
    "#             grouped_df = df.pivot(index='Frame', columns='Sub_ID', values='Speak')\n",
    "#             grouped_df = grouped_df.reset_index()\n",
    "\n",
    "#             # Renaming columns\n",
    "#             grouped_df = grouped_df.rename(columns=lambda x: 'Sub Id: ' + str(x) if x in sub_ids else x)\n",
    "\n",
    "#             # Adding a column that represents the number of speakers speaking in this frame.\n",
    "#             grouped_df['Active Speaker Count'] = grouped_df.iloc[:, 1:].sum(axis=1)\n",
    "            \n",
    "#             grouped_df.to_csv(f'{speech_data_directory}/{filename}',index=False)\n",
    "#         except Exception as e:\n",
    "#             print(f\"An error occurred for file: {filename}:\", e)\n",
    "            \n",
    "# speech_formatting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12939760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(df):\n",
    "    filtered_columns = df[speaker_cols]\n",
    "    df['speech_pattern'] = filtered_columns.astype(str).apply(lambda x: ','.join(x), axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def identify_tss_disjoint(df):\n",
    "    \n",
    "    queue = []\n",
    "    df['tss_disjoint'] = 0\n",
    "    df['queue_disjoint'] = ''\n",
    "\n",
    "    previous_speaker_set = set()\n",
    "    previous_speaker_pattern = ''\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        df.at[index, 'queue_disjoint'] = str(queue)\n",
    "        \n",
    "            \n",
    "        if previous_speaker_pattern and row['speech_pattern'] != previous_speaker_pattern :\n",
    "\n",
    "            new_speaker_set = set()\n",
    "            for speaker in speaker_cols:\n",
    "                if row[speaker]:\n",
    "                    new_speaker_set.add(speaker)\n",
    "                    \n",
    "            difference_set = new_speaker_set - previous_speaker_set \n",
    "            if len(difference_set):\n",
    "                queue += list(difference_set)\n",
    "\n",
    "                while len(queue)>3:\n",
    "                    queue.pop(0)\n",
    "\n",
    "                if len(set(queue)) == 3:\n",
    "                    df.at[index, 'tss_disjoint'] = 1\n",
    "                    queue = []\n",
    "\n",
    "            previous_speaker_set = new_speaker_set\n",
    "            \n",
    "        previous_speaker_pattern = row['speech_pattern']\n",
    "        \n",
    "            \n",
    "            \n",
    "    return df\n",
    "\n",
    "def identify_tss_disjoint_sp(df, MEDIAN_SP_THRESHOLD):\n",
    "    \n",
    "    queue = []\n",
    "    df[f'tss_disjoint_sp_{MEDIAN_SP_THRESHOLD}'] = 0\n",
    "    df[f'queue_disjoint_sp_{MEDIAN_SP_THRESHOLD}'] = ''\n",
    "\n",
    "    previous_speaker_set = set()\n",
    "    previous_speaker_pattern = ''\n",
    "    \n",
    "    pause_frame_count = 0\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        df.at[index, f'queue_disjoint_sp_{MEDIAN_SP_THRESHOLD}'] = str(queue)\n",
    "        \n",
    "        if row['Active Speaker Count'] == 0:\n",
    "            pause_frame_count += 1\n",
    "            \n",
    "            \n",
    "        if previous_speaker_pattern and row['speech_pattern'] != previous_speaker_pattern :\n",
    "            \n",
    "            if MEDIAN_SP_THRESHOLD is not None and pause_frame_count > MEDIAN_SP_THRESHOLD:\n",
    "                queue = []\n",
    "                pause_frame_count = 0\n",
    "\n",
    "            new_speaker_set = set()\n",
    "            for speaker in speaker_cols:\n",
    "                if row[speaker]:\n",
    "                    new_speaker_set.add(speaker)\n",
    "                    \n",
    "            difference_set = new_speaker_set - previous_speaker_set \n",
    "            if len(difference_set):\n",
    "                queue += list(difference_set)\n",
    "\n",
    "                while len(queue)>3:\n",
    "                    queue.pop(0)\n",
    "\n",
    "                if len(set(queue)) == 3:\n",
    "                    df.at[index, f'tss_disjoint_sp_{MEDIAN_SP_THRESHOLD}'] = 1\n",
    "                    queue = []\n",
    "\n",
    "            previous_speaker_set = new_speaker_set\n",
    "            \n",
    "        previous_speaker_pattern = row['speech_pattern']\n",
    "        \n",
    "            \n",
    "            \n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e71a4a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binning(df):\n",
    "    \n",
    "    # Calculate the number of bins required\n",
    "    bin_size = 1800\n",
    "    num_bins = (len(df) - 1) // bin_size + 1\n",
    "\n",
    "    # Create an empty list to store the DataFrames for each bin\n",
    "    result_dfs = []\n",
    "\n",
    "    # Loop through each bin and calculate the sum for each column\n",
    "    for bin_num in range(num_bins):\n",
    "        start_index = bin_num * bin_size\n",
    "        end_index = (bin_num + 1) * bin_size\n",
    "        bin_df = df.iloc[start_index:end_index]\n",
    "        bin_sum = bin_df.sum()\n",
    "        bin_sum['Frame'] = f\"{bin_num * bin_size + 1}-{min((bin_num + 1) * bin_size, len(df))}\"\n",
    "        result_dfs.append(bin_sum)\n",
    "\n",
    "    # Concatenate all the DataFrames in the result_dfs list into a single DataFrame\n",
    "    result_df = pd.concat(result_dfs, axis=1).T\n",
    "\n",
    "    # Set the 'Frame' column as the index of the result DataFrame\n",
    "    result_df.set_index('Frame', inplace=True)\n",
    "    result_df = result_df.reset_index(drop=True)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "\n",
    "def binning_plus(df):\n",
    "    # Calculate the number of bins required\n",
    "    bin_sizes = [5400] + [1800] * ((len(df) - 5400 - 1) // 1800 + 1)\n",
    "\n",
    "    # Create an empty list to store the DataFrames for each bin\n",
    "    result_dfs = []\n",
    "\n",
    "    # Loop through each bin and calculate the sum for each column\n",
    "    for bin_num, bin_size in enumerate(bin_sizes):\n",
    "        start_index = bin_num * bin_size\n",
    "        end_index = (bin_num + 1) * bin_size\n",
    "        bin_df = df.iloc[start_index:end_index]\n",
    "        bin_sum = bin_df.sum()\n",
    "        bin_sum['Frame'] = f\"{bin_num * bin_size + 1}-{min((bin_num + 1) * bin_size, len(df))}\"\n",
    "        result_dfs.append(bin_sum)\n",
    "\n",
    "    # Concatenate all the DataFrames in the result_dfs list into a single DataFrame\n",
    "    result_df = pd.concat(result_dfs, axis=1).T\n",
    "\n",
    "    # Set the 'Frame' column as the index of the result DataFrame\n",
    "    result_df.set_index('Frame', inplace=True)\n",
    "    result_df = result_df.reset_index(drop=True)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "\n",
    "def save_dataframe_as_bar_graph(df, save_filepath, title, ylabel, xlabel=\"Minute\"):\n",
    "    # Set a custom color palette for the bars\n",
    "    colors = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\", \"#8c564b\", \"#e377c2\", \"#7f7f7f\", \"#bcbd22\", \"#17becf\"]\n",
    "    sns.set_palette(colors)\n",
    "\n",
    "    # Increase the width of the bars\n",
    "    bar_width = 0.8\n",
    "    \n",
    "    df.set_index('Minute', inplace=True)\n",
    "\n",
    "    # Plotting the bar graph with or without outlining the bars\n",
    "    ax = df.plot(kind='bar', figsize=(10, 6), width=bar_width)\n",
    "\n",
    "    # Adding labels and title\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "\n",
    "    # Displaying the legend with custom labels\n",
    "    plt.legend(title='Columns', labels=df.columns)\n",
    "\n",
    "    # Removing the top and right spines for aesthetics\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "#     Show the plot\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "    # Save the graph at the specified location\n",
    "    plt.savefig(save_filepath)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cde29a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:22<00:00,  5.67it/s]\n"
     ]
    }
   ],
   "source": [
    "tss_list = []\n",
    "speaker_cols = []\n",
    "\n",
    "MEDIAN_SP_THRESHOLDS = [2, 32, 34.9, 78.5, 93]\n",
    "MEDIAN_SP_THRESHOLDS.sort(reverse=True)\n",
    "\n",
    "for filename in tqdm(os.listdir(speech_data_directory)):\n",
    "    if '.csv' not in filename:\n",
    "        continue\n",
    "    file_path = speech_data_directory +'/'+ filename\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    speaker_cols = []\n",
    "    for col in df.columns:\n",
    "        if 'Sub Id' in col:\n",
    "            speaker_cols.append(col)\n",
    "    \n",
    "    df = prep(df)\n",
    "    df = identify_tss_disjoint(df)\n",
    "    \n",
    "    for MEDIAN_SP_THRESHOLD in MEDIAN_SP_THRESHOLDS:\n",
    "        df = identify_tss_disjoint_sp(df, MEDIAN_SP_THRESHOLD)\n",
    "        \n",
    "    df = df[['Frame', 'tss_disjoint','tss_disjoint_sp_93','tss_disjoint_sp_78.5', \n",
    "       'tss_disjoint_sp_34.9',  'tss_disjoint_sp_32', 'tss_disjoint_sp_2' ]]\n",
    "    \n",
    "    df.columns = ['Frame', 'Disjoint TSS Count','Disjoint TSS Count (Pause <= 93)',\n",
    "       'Disjoint TSS Count (Pause <= 78.5)', \n",
    "       'Disjoint TSS Count (Pause <= 34.9)',  'Disjoint TSS Count (Pause <= 32)', 'Disjoint TSS Count (Pause <= 2)' ]\n",
    "    \n",
    "    \n",
    "    custom_bin_df = binning_plus(df)\n",
    "    df = binning(df)\n",
    "    \n",
    "    df.insert(0, 'Minute', range(1, len(df) + 1))\n",
    "    custom_bin_df.insert(0, 'Minute', [f\"0-3\" if i == 3 else str(i) for i in range(3,len(custom_bin_df)+3)])\n",
    "\n",
    "    group, speakers = filename[:-4].split('_', 1)\n",
    "    df.to_csv(f\"{binned_tss_directory}/{filename}\", index=False)\n",
    "    save_dataframe_as_bar_graph(df, f\"{binned_tss_directory}/{filename[:-4]}_graph\", f\"Group: {group} ({speakers})\", \"Triadic Speech Seq. Count\")\n",
    "    \n",
    "    custom_bin_df.to_csv(f\"{custom_binned_tss_directory}/{filename}\", index=False)\n",
    "    save_dataframe_as_bar_graph(custom_bin_df, f\"{custom_binned_tss_directory}/{filename[:-4]}_graph\", f\"Group: {group} ({speakers})\", \"Triadic Speech Seq. Count\")\n",
    "#     display(df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cd7136",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
