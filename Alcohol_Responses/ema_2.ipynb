{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62e8a406-23f6-4d5a-8ff8-b2e92e3ee1f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ee84596-fac9-4bda-bedc-e87fd399a3e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_directory = '/Users/sauravyadav/Documents/Repos/Datasets/Drinking_Surveys/output/prelim_data_0.csv'\n",
    "submission_info_directory = \"/Users/sauravyadav/Documents/Repos/Datasets/Drinking_Surveys/EMA Weekends_FINAL.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baf075a8-2920-4ccf-9a03-e62cdee87c51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/35/8nzwnddx74qg4p54k0q2v_0r0000gn/T/ipykernel_14311/3544748107.py:1: DtypeWarning: Columns (28,29,30,31,32,33,34,35,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_directory)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(input_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6247b6ec-7239-404a-a5c7-fc571f84caf6",
   "metadata": {},
   "source": [
    "### TO DO\n",
    "- ~~Normalize Date Format~~\n",
    "- ~~Float to Int~~\n",
    "- ~~Create and Insert Columns : \n",
    "    - ~~'Brst': 'Burst'~~,\n",
    "    - ~~'Wknd': 'Weekend'~~,\n",
    "    - ~~'Day': 'Day Within Weekend'~~,\n",
    "    - ~~'DrnkNum_combine',\n",
    "    - ~~'DrnkNum_cumulative',\n",
    "- MR_DrnkDur column\n",
    "- MR_wake column\n",
    "- ~~Consider additional columns to add:\n",
    "    - ~~Date of Drinking Session\n",
    "    - ~~Group\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fd01b4-8baa-47d2-a291-6bf3bdf4d3aa",
   "metadata": {},
   "source": [
    "### Uniform Date Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c02711f-ac66-4b63-96ed-08ba99b10317",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "date_columns = [col for col in df.columns if 'date' in col.lower()]\n",
    "formats = ['%d/%m/%Y', '%Y-%d-%m %H:%M:%S']\n",
    "# Function to try parsing the date with multiple formats\n",
    "def parse_date(date_str):\n",
    "    for fmt in formats:\n",
    "        try:\n",
    "            return pd.to_datetime(date_str, format=fmt)\n",
    "        except ValueError:\n",
    "            # print(f'String: {date_str} Format failure: {fmt}')\n",
    "            pass\n",
    "    print(date_str)\n",
    "    return pd.NaT  # Return NaT (Not-a-Time) for unparseable dates\n",
    "\n",
    "# df[(df['TrigDate'].str.contains('-'))]['TrigDate'].sort_values(ascending=False)\n",
    "# df['TrigDate'].sample(5)\n",
    "\n",
    "# Apply the parse_date function to the 'DateColumn'\n",
    "for date_col in date_columns:\n",
    "    df[date_col] = df[date_col].apply(parse_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8993b89-8c6c-49f0-9488-fe94b1f9121b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Remove Decimal Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbb64d56-7f2b-4758-a2a3-72b1e2354325",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "int_columns = ['UI_DrnkFin', 'UI_DrnkNum', 'DrnkNum', 'Plsur', 'Rliev', 'IntxNow',\n",
    "       'MorAlc', 'enrgz', 'excit', 'sedat', 'slotht', 'slug', 'up', 'crntloc',\n",
    "       'wthothr', 'NumOth', 'OthTyp', 'OthWho', 'EnjInt', 'vrtint', 'vrtoth', 'vrtwho', 'vrtenj', 'ActCld',\n",
    "       'ActAcc', 'OthCld', 'OthAcc', 'Vrtl', 'AlnLke', 'AlnGd', 'WshOth',\n",
    "       'lnly', 'rjct', 'incl', 'acpt', 'vrtcld', 'VrtAcc', 'VrtOthCld',\n",
    "       'VrtOthAcc', 'NotInt', 'WshInt', 'UI_NtInt_lnly', 'UI_NtInt_rjct',\n",
    "       'UI_NtInt_incl', 'UI_NtInt_acpt', 'said', 'spent', 'impt', 'spur']\n",
    "\n",
    "for col in int_columns:\n",
    "    df[col] = df[col].astype('Int64', errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d04428-5027-42ce-978d-e1f857249e50",
   "metadata": {},
   "source": [
    "### Convert Date to UTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b40ec40-3173-4a71-bb7b-cc096b06db80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['SubDate'] = df['SubDate'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da212793-b782-427c-8df9-e32c72685e81",
   "metadata": {},
   "source": [
    "### New Columns: Burst,Weekend, Day Within Weekend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1394e8d8-451b-4557-ba70-ccc6ee8c390d",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_info_df = pd.read_excel(submission_info_directory, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24d4217d-aed0-4e81-afc7-1f6f309c926d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMA Weekend 1</th>\n",
       "      <th>EMA Weekend 2</th>\n",
       "      <th>EMA Weekend 3</th>\n",
       "      <th>EMA Weekend 4</th>\n",
       "      <th>EMA Weekend 5</th>\n",
       "      <th>EMA Weekend 6</th>\n",
       "      <th>SubID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Thurs 4/5/18-4/8/18</td>\n",
       "      <td>Thurs 4/12/18-4/15/18</td>\n",
       "      <td>September 2018</td>\n",
       "      <td>September 2018</td>\n",
       "      <td>March 2019</td>\n",
       "      <td>March 2019</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          EMA Weekend 1          EMA Weekend 2   EMA Weekend 3  \\\n",
       "14  Thurs 4/5/18-4/8/18  Thurs 4/12/18-4/15/18  September 2018   \n",
       "\n",
       "     EMA Weekend 4 EMA Weekend 5 EMA Weekend 6  SubID  \n",
       "14  September 2018    March 2019    March 2019   2009  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_info_df = date_info_df[~date_info_df['Sub ID'].isna()].reset_index(drop=True)\n",
    "date_info_df['SubID'] = date_info_df['Sub ID'].astype('Int64', errors='ignore')\n",
    "date_info_df = date_info_df.drop(columns=['Date of Drinking Session ', 'Group', 'Sub ID']).reset_index(drop=True)\n",
    "date_info_df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3440da81-31a0-42e5-b8c3-664828004538",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/35/8nzwnddx74qg4p54k0q2v_0r0000gn/T/ipykernel_14311/2367939162.py:75: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  date_info_df['Submission_Date'] = date_info_df['Submission_Date'].astype('datetime64[ns]')\n"
     ]
    }
   ],
   "source": [
    "date_info_df = pd.melt(date_info_df, id_vars=['SubID'], var_name='Weekend', value_name='Submission_Range')\n",
    "date_info_df['Weekend'] = date_info_df['Weekend'].str.replace('EMA Weekend', '').astype(int)\n",
    "\n",
    "def expand_year(d):\n",
    "    date_parts = d.split('/')\n",
    "    if len(date_parts)==3:\n",
    "        year = date_parts[2]\n",
    "        if len(year)==2:\n",
    "            year = f'20{year}'\n",
    "            d = f'{d[:-2]}{year}'\n",
    "    return d\n",
    "    \n",
    "def expand_date_range(row):\n",
    "    \n",
    "    try:\n",
    "        if isinstance(row['Submission_Range'], datetime):\n",
    "            return []\n",
    "        date_parts = row['Submission_Range'].split('-')\n",
    "        if len(date_parts)<=1:\n",
    "            return []\n",
    "        start_date_parts = date_parts[0].strip().split(' ')\n",
    "        end_date_parts = date_parts[1].strip().split(' ')\n",
    "        \n",
    "        start_date = start_date_parts[1]\n",
    "        end_date = end_date_parts[1] if len(end_date_parts)==2 else end_date_parts[0]\n",
    "        \n",
    "        start_date = expand_year(start_date)\n",
    "        end_date = expand_year(end_date)\n",
    "            \n",
    "        if len(start_date.split('/'))==2 and len(end_date.split('/'))==2:\n",
    "            print(f'SubID: {row[\"SubID\"]} {row[\"Submission_Range\"]} Range End Date Year: {end_date} Start Year: {start_date}')\n",
    "            return []\n",
    "        elif len(start_date.split('/'))==2:\n",
    "            end_date_month, end_date_date ,end_date_year = end_date.split('/')\n",
    "            start_date_year = end_date_year \n",
    "            if end_date_month=='1' and end_date_date in['1','2','3']:\n",
    "                start_date_year = str(int(end_date_year) - 1)\n",
    "            start_date = start_date + f'/{start_date_year}'\n",
    "        \n",
    "        elif len(end_date.split('/'))==2:\n",
    "            start_date_month, start_date_date, start_date_year = start_date.split('/')\n",
    "            end_date_year = start_date_year\n",
    "            if start_date_month=='12' and start_date_date in ['29','30','31']:\n",
    "                end_date_year = str(int(start_date_year)+1)\n",
    "            \n",
    "            end_date = end_date + f'/{end_date_year}'\n",
    "        \n",
    "        try:\n",
    "            start_date = pd.to_datetime(start_date, format='%m/%d/%Y')\n",
    "            end_date = pd.to_datetime(end_date, format='%m/%d/%Y')\n",
    "        except ValueError:\n",
    "            print(f'{start_date} and {end_date}')\n",
    "            \n",
    "        # date_range = pd.date_range(start_date, end_date, freq='D')\n",
    "        date_range = pd.date_range(start_date, periods=4, freq='D')\n",
    "        res = [date.strftime('%a %m/%d/%y') for date in date_range]\n",
    "        \n",
    "        if len(res)!=4:\n",
    "            print(row)\n",
    "            print(res)\n",
    "            print(f\"!! RANGE IS {row['Submission_Range']}, DATES ARE {start_date} and {end_date}\")\n",
    "        \n",
    "        return res\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        display(row)\n",
    "        print(e)\n",
    "        return []\n",
    "\n",
    "date_info_df['Submission_Date'] = date_info_df.apply(expand_date_range, axis=1)\n",
    "date_info_df = date_info_df.explode('Submission_Date').reset_index(drop=True)\n",
    "date_info_df['Burst'] = np.ceil(date_info_df['Weekend'] / 2).astype(int)\n",
    "date_info_df['Day'] = pd.to_datetime(date_info_df['Submission_Date'], format='%a %m/%d/%y').dt.strftime('%a')\n",
    "date_info_df = date_info_df[~date_info_df['Submission_Date'].isna()]\n",
    "date_info_df['Submission_Date'] = date_info_df['Submission_Date'].astype('datetime64[ns]')\n",
    "# date_info_df = date_info_df.drop(columns=['Submission_Range', 'Submission_Date']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa4d1319-9c95-4069-90f0-db55e3effc8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "date_info_df = date_info_df.drop(columns=['Submission_Range'])\n",
    "res_df = df.merge(date_info_df, left_on=['SubID','SubDate'], right_on=['SubID', 'Submission_Date'])\n",
    "res_df = res_df.drop(columns=['Submission_Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a889e753-9dd7-4be8-9563-9306a43eb573",
   "metadata": {},
   "source": [
    "### New Columns: 'DrnkNum_combine', 'DrnkNum_cumulative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13a7a2b9-7194-45ad-927f-b4ba0229ca43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_df['DrnkNum_combine'] = res_df.apply(lambda x: x['DrnkNum'] - 1 if (pd.notnull(x['DrnkNum']) and x['DrnkNum'] > 1 and x['RespType'] != 'Missed' and x['SurvName'] == 'Drinking Follow-Ups')  else (x['UI_DrnkNum'] if (x['SurvName'] == 'After Your 1st Drink' and x['RespType'] != 'Missed')  else (0 if (pd.notnull(x['DrnkNum']) and x['DrnkNum'] == 1 and x['RespType'] != 'Missed') else None)), axis = 1)\n",
    "# res_df['DrnkNum_combine'] = res_df['DrnkNum_combine'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cda31a5-fccb-4d51-9130-d945c8306d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = res_df.sort_values(by=['SubID', 'SubDate', 'SubTime', 'SurvName']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c60de7d1-69b4-4fd8-9827-c4985ddbda0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped = res_df.groupby(['SubID', 'Weekend', 'Burst'])\n",
    "# res_df['DrnkNum_cumulative'] = None\n",
    "\n",
    "# for group_name, group_df in grouped:\n",
    "#     cumulativeDrinkNum = 0\n",
    "#     for index, row in group_df.iterrows():\n",
    "        \n",
    "#         if row['SurvName'] == 'After Your 1st Drink':\n",
    "#             cumulativeDrinkNum = 0\n",
    "\n",
    "#         if row['RespType'] == 'Missed':\n",
    "#             continue\n",
    "            \n",
    "#         cumulativeDrinkNum += 0 if pd.isna(row['DrnkNum_combine']) else row['DrnkNum_combine']\n",
    "#         res_df.at[index, 'DrnkNum_cumulative'] = cumulativeDrinkNum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dd0a3a-ee55-42ea-b13e-5a52383d16b4",
   "metadata": {},
   "source": [
    "### Finishing up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8610c57-46c2-4f5a-b7bb-f52e21cef2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = res_df[['SubID','Burst', 'Weekend', 'Day', 'RespID', 'RespType', 'UserID', 'SurvName', 'SurvType',\n",
    "       'InitDate', 'InitTime', 'SubDate', 'SubTime', 'TrigDate', 'TrigTime',\n",
    "       'UI_DrnkFin', 'UI_DrnkNum', 'DrnkNum', 'Plsur', 'Rliev', 'IntxNow',\n",
    "       'MorAlc', 'enrgz', 'excit', 'sedat', 'slotht', 'slug', 'up', 'crntloc',\n",
    "       'othrloc', 'wthothr', 'NumOth', 'OthTyp', 'OthWho', 'EnjInt', 'ActCld',\n",
    "       'ActAcc', 'OthCld', 'OthAcc', 'Vrtl', 'AlnLke', 'AlnGd', 'WshOth',\n",
    "       'lnly', 'rjct', 'incl', 'acpt','vrtint', 'vrtoth',\n",
    "        'vrtwho', 'vrtenj', 'vrtcld', 'VrtAcc', 'VrtOthCld',\n",
    "       'VrtOthAcc', 'NotInt', 'WshInt', 'UI_NtInt_lnly', 'UI_NtInt_rjct',\n",
    "       'UI_NtInt_incl', 'UI_NtInt_acpt', 'said', 'spent', 'impt', 'spur']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a854149-8792-4712-8e8c-ef3e53ed82c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res_df.to_csv('/Users/sauravyadav/Documents/Repos/Datasets/Drinking_Surveys/output/data_draft.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad1550c-1f26-46fe-88c0-5a5ee1fb56f9",
   "metadata": {},
   "source": [
    "### See next jupyter part...."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
